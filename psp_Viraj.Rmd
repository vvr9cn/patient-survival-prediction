---
title: "Patient Survival Prediction Project"
author: "Adam Crawford, Adam Baer, Austin Funcheon, Viraj Rane"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Preparation

Import data	                                                          Crawford
Store data into a dataframe	                                          Crawford
Perform high level review of data	                                    Crawford
Run prelim statistics on data	                                        Crawford
Review data for missing data	                                        Baer
Identify High integrity predictors                                    Baer
Remove unhelpful predictors (Such as, perhaps, ID)                    Baer
Transform data for usability	                                        Rane
Visualize data	                                                      Baer
Identify if any continuous data is non-normal	                        Funcheon

Identify if any discrete data is heavily unbalanced                   Rane
Consider data normalization	                                          Rane
Consider balancing data	                                              Funcheon
Consider transformation of some fields, such as log transformation	  Funcheon
Cleanse data                                                        	Funcheon
Format datafields into data levels (if needed)                    	  Funcheon
Run statistical analysis of predictors  .                           	Rane
Prune unhelpful predictors to drive to parsimonous model.	            Rane
Evaluate for collinearity	                                            Baer
Reduce model for predictors that have high colinearity	              Baer
Re-run statistical analysis on reduced model	                        Crawford
Break data up into train test and validate data set	                  Crawford
Run model type #1	                                                    Crawford
Evaluate results of model type #1	                                    Crawford
Run model type #2	                                                    Crawford
Evaluate results of model type #2	                                    Crawford
Run model type #3	                                                    Rane
Evaluate results of model type #3	                                    Rane
Run model type #4	                                                    Funcheon
Evaluate results of model type #4	                                    Funcheon
Tune parameters of favored model                                    	Rane
Validate favored model on Test group                                	Rane


```{r}
# Importing all libraries
library(caret)
library(ggplot2)
library(tidyr)
library(dplyr)

```

# 1. Load the Data
```{r}
df <- read.csv("dataset.csv")
# view the structure of data
str(df)
```

# Data Cleaning

Dropping all irrelevant columns / selecting all valid columns in the data set.
●	ethnicity: The common national or cultural tradition which the person belongs to
**Ethnicity has no significance in predicting patient's survival**

●	encounter_id - Unique identifier associated with a patient unit stay
●	patient_id: Unique identifier associated with a patient
●	hospital_id: Unique identifier associated with a hospital
●	icu_id: A unique identifier for the unit to which the patient was admitted
**The above variables that represent identifications and will be of no use to us.**

●	apache_post_operative: The APACHE operative status; 1 for post-operative, 0 for non-operative
**The variable is of low importance justifying apache operative status as yes or no**

●	gcs_unable_apache: Whether the Glasgow Coma Scale was unable to be assessed due to patient sedation
**The above apache variables seem non-critical to be considered for predictive purpose.**

●	d1_diasbp_noninvasive_max: The patient's highest diastolic blood pressure during the first 24 hours of their unit stay, non-invasively measured
●	d1_diasbp_noninvasive_min: The patient's lowest diastolic blood pressure during the first 24 hours of their unit stay, non-invasively measured

●	d1_sysbp_noninvasive_max: The patient's highest systolic blood pressure during the first 24 hours of their unit stay, invasively measured
●	d1_sysbp_noninvasive_min: The patient's lowest systolic blood pressure during the first 24 hours of their unit stay, invasively measured

●	h1_diasbp_noninvasive_max: The patient's highest diastolic blood pressure during the first hour of their unit stay, invasively measured
●	h1_diasbp_noninvasive_min: The patient's lowest diastolic blood pressure during the first hour of their unit stay, invasively measured

●	h1_sysbp_noninvasive_max: The patient's highest systolic blood pressure during the first hour of their unit stay, non-invasively measured
●	h1_sysbp_noninvasive_min: The patient's lowest systolic blood pressure during the first hour of their unit stay, non-invasively measured

**The d1 and h1 highest and lowest diastolic and systolic blood pressure variable measures are considered, but their noninvasive measures are excluded to avoid the issue of mulicollinearity between the variables.**

●	d1_mbp_noninvasive_max: The patient's highest mean blood pressure during the first 24 hours of their unit stay, non-invasively measured
●	d1_mbp_noninvasive_min: The patient's lowest mean blood pressure during the first 24 hours of their unit stay, non-invasively measured

●	h1_mbp_noninvasive_max: The patient's highest mean blood pressure during the first hour of their unit stay, non-invasively measured
●	h1_mbp_noninvasive_min: The patient's lowest mean blood pressure during the first hour of their unit stay, non-invasively measured

**The d1 and h1 highest and lowest mean blood pressure (MBP) variable measures are considered, but their noninvasive measures are excluded to avoid the issue of mulicollinearity between the variables.**

●	d1_glucose_max: The highest glucose concentration of the patient in their serum or plasma during the first 24 hours of their unit stay
●	d1_glucose_min: The lowest glucose concentration of the patient in their serum or plasma during the first 24 hours of their unit stay
●	d1_potassium_max: The highest potassium concentration for the patient in their serum or plasma during the first 24 hours of their unit stay
●	d1_potassium_min: The lowest potassium concentration for the patient in their serum or plasma during the first 24 hours of their unit stay

**Glucose and potassium concentrations are considered are non critical measures for estimating the apache 4a score and patients survival and admission in the ICU ward**

●	aids: Whether the patient has a definitive diagnosis of acquired immune deficiency syndrome (AIDS) (not HIV positive alone)
●	cirrhosis: Whether the patient has a history of heavy alcohol use with portal hypertension and varices, other causes of cirrhosis with evidence of portal hypertension and varices, or biopsy proven cirrhosis.
●	diabetes_mellitus: Whether the patient has been diagnosed with diabetes, either juvenile or adult onset, which requires medication.
●	hepatic_failure: Whether the patient has cirrhosis and additional complications including jaundice and ascites, upper GI bleeding, hepatic encephalopathy, or coma.
●	immunosuppression: Whether the patient has their immune system suppressed within six months prior to ICU admission for any of the following reasons: radiation therapy, chemotherapy, use of non-cytotoxic immunosuppressive drugs, high dose steroids (at least 0.3 mg/kg/day of methylprednisolone or equivalent for at least 6 months).
●	leukemia: Whether the patient has been diagnosed with acute or chronic myelogenous leukemia, acute or chronic lymphocytic leukemia, or multiple myeloma.
●	lymphoma: Whether the patient has been diagnosed with non-Hodgkin lymphoma.
●	solid_tumor_with_metastasis: Whether the patient has been diagnosed with any solid tumor carcinoma (including malignant melanoma) which has evidence of metastasis.

**The above variables have data that indicate whether a patient has any one or more ailments, they do not show any measures of the ailments, and therefore does not make them relevant for consideration**

●	apache_3j_bodysystem: Admission diagnosis group for APACHE III
●	apache_2_bodysystem: Admission diagnosis group for APACHE II

**The bodysystem apache variables only categorizes a patient falling into one of the categories related to past or current condition for admission into the hospital**

Based on the above explanation, selecting all useful variables.
```{r}
data <- df %>%
  select(age, bmi, elective_surgery, gender, height, icu_admit_source, icu_stay_type, icu_type, pre_icu_los_days, weight, apache_2_diagnosis, apache_3j_diagnosis, arf_apache, gcs_eyes_apache, gcs_motor_apache, gcs_verbal_apache, heart_rate_apache, intubated_apache, map_apache, resprate_apache, temp_apache, ventilated_apache, d1_diasbp_max, d1_diasbp_min, d1_heartrate_max, d1_heartrate_min, d1_mbp_max, d1_mbp_min, d1_resprate_max, d1_resprate_min, d1_spo2_max, d1_spo2_min, d1_sysbp_max, d1_sysbp_min, d1_temp_max, d1_temp_min, h1_diasbp_max, h1_diasbp_min, h1_heartrate_max, h1_heartrate_min, h1_mbp_max, h1_mbp_min, h1_resprate_max, h1_resprate_min, h1_spo2_max, h1_spo2_min, h1_sysbp_max, h1_sysbp_min, apache_4a_hospital_death_prob, apache_4a_icu_death_prob, hospital_death)

data <- data.frame(data)
str(data)
```

The have now selected 51 variables with 91713 observations to perform analysis.

Now let's run a summary statistic on the data
```{r}
summary(data)
```

Calculating the total number of NULL values or nas in the data set.
```{r}
sum(is.na(data))
```


From the summary statistics we can see that the data set has 99294 missing values, we'll remove the missing values.

```{r}
# removing the missing values
data %>% na.omit(data)
```

# Data conversion
```{r}
#converting categorical variables to numeric

data$gender <- ifelse(as.factor(data$gender)=="M",1,0)
data$gender <- as.numeric(as.character(data$gender))

data$icu_admit_source <- as.factor(data$icu_admit_source)
data$icu_admit_source <- unclass(data$icu_admit_source)
data$icu_admit_source <- as.numeric(as.character(data$icu_admit_source))

data$icu_stay_type <- as.factor(data$icu_stay_type)
data$icu_stay_type <- unclass(data$icu_stay_type)
data$icu_stay_type <- as.numeric(as.character(data$icu_stay_type))

data$icu_type <- as.factor(data$icu_type)
data$icu_type <- unclass(data$icu_type)
data$icu_type <- as.numeric(as.character(data$icu_type))
```

# Dealing with missing values
```{r}
#missing values

data[is.na(data)] <- min(data, na.rm = TRUE)
sum(is.na(data))
```


# Confirming columns and observation duplication
```{r}
sum(duplicated(data))
sum(duplicated(as.list(data)))
```

From the above result, we can see that the data set does not have any duplicate variables and observations.



# BMI, Height, and Weight
We first check the missing values in BMI and height columns.
```{r}
head(data$bmi)
head(data$height)
head(data$weight)

sum(is.na(data$bmi))
sum(is.na(data$height))
sum(is.na(data$weight))
```

Next we round the decimals to 2.
```{r, include=FALSE}

round(data$bmi, digits = 2)
round(data$height, digits = 2)
round(data$weight, digits = 2)

```

Next we use the min function to calculate the minimum bmi and height. And we use the min values calculated by the function to fill the missing values
```{r}
#bmi
data$bmi[is.na(data$bmi)] <- min(data$bmi, na.rm = TRUE)
sum(is.na(data$bmi))
#height
data$height[is.na(data$height)] <- min(data$height, na.rm = TRUE)
sum(is.na(data$height))
#weight
data$weight[is.na(data$weight)] <- min(data$weight, na.rm = TRUE)
sum(is.na(data$weight))
```


```{r}
# mode function
getmode <- function(x, na.rm= FALSE){
  u <- unique(x)
  tab <- tabulate(match(x,u))
  u[tab == max(tab)]
}

```

# Data Exploration and Visualization

The type of ICU stay and ICU type

```{r}
library(ggExtra)
library(gridExtra)
p <- ggplot(data, aes(x = apache_2_diagnosis, y = apache_3j_diagnosis)) +
  geom_point() +
  theme(legend.position = "none")

p1 <- ggMarginal(p, type = "histogram", fill = "green")

p2 <- ggMarginal(p, type = "density", fill = "blue")

p3 <- ggMarginal(p, type = "boxplot", fill = "orange")

grid.arrange(p1, p2, p3, ncol = 3)
```

ICU stay and ICU type bar plot

```{r}
# Grouped Bar Plot
counts <- table(data$icu_stay_type, data$icu_type)
barplot(counts, main="Icu type and Icu Stay type",
  xlab="No. of ICU types", ylab= "No. of ICU stays", col=c("darkblue","red"),
  legend = rownames(counts), beside=TRUE)
```


A scatter plot matrix to show the relationship between the response and all predictor variables

```{r}
pairs(~hospital_death + age + bmi + elective_surgery + gender, data = data, col=ifelse(data$hospital_death ==1, 'green', 'black'))

pairs(~hospital_death + height + icu_admit_source + icu_stay_type + pre_icu_los_days + weight, data = data, col=ifelse(data$hospital_death ==1, 'green', 'black'))

pairs(~hospital_death + apache_2_diagnosis + apache_3j_diagnosis + heart_rate_apache + apache_4a_hospital_death_prob + apache_4a_icu_death_prob, data = data, col=ifelse(data$hospital_death ==1, 'green', 'black'))
```
# Scatter plot

```{r}
# scatter plot apache 4a hospital death probability and hospital death

ggplot(data, aes(apache_4a_icu_death_prob,apache_4a_hospital_death_prob)) + geom_point(alpha = 0.3) + geom_smooth(method = lm) + labs(x = "Apache 4a ICU death prob", y = "Apache 4a hospital death prob")
```

# Correlation plot
```{r}
# correlation plot
library(corrplot)
data_plot <- data %>%
  select(hospital_death, age, bmi, elective_surgery, gender, height, icu_admit_source, icu_stay_type, pre_icu_los_days, weight, apache_2_diagnosis, apache_3j_diagnosis, heart_rate_apache, apache_4a_hospital_death_prob, apache_4a_icu_death_prob)
data_plot <- data.frame(data_plot)
M <- cor(data_plot)
corrplot(M, method="number")
corrplot(M, method= "circle")
```
# Grouped box plots

```{r}
# Box plots of Apache scores
library(reshape)
bplot <- melt(data = data_plot, measure.vars = c(11:15), variable_name = "variable")

ggplot(bplot, aes(x = variable, y = value, fill = "icu_admit_source")) +
  geom_boxplot() + facet_wrap(~ variable, scales = "free", ncol = 5) + labs(title = "Boxplots of apache scores")
```

# Wordclouds

Apache_3j Bodysystem
```{r}
library(tm)
library(wordcloud)
library(SnowballC)

mooncloud <- df$apache_3j_bodysystem

wordcloud(mooncloud, scale = c(10,0.7),
          max.words=100,
          random.order=FALSE,
          rot.per=0.35,
          use.r.layout = FALSE,
          colors = brewer.pal(8, "Dark2"))
```
Apache_2 Bodysystem
```{r}
suncloud <- df$apache_2_bodysystem

wordcloud(suncloud, scale = c(10,0.7),
          max.words=100,
          random.order=FALSE,
          rot.per=0.35,
          use.r.layout = FALSE,
          colors = brewer.pal(8, "Dark2"))
```

# Predictive modeling

```{r}
library(doParallel)
cl <- makePSOCKcluster(detectCores() - 1)
registerDoParallel(cl)
```

Viewing the death ratio of the number of patients admitted in a hospital, where 1 = dead, 0 = living
```{r}
ggplot(data, aes(as.factor(hospital_death))) + geom_bar() + labs(x = "Hospital death")
```

From the above bar plot, we can see that the data in the response variable hospital_death is imbalanced, as the number of observations are much larger, therefore we choose to undersample the data to handling the imbalance issue.

#UnderSampling the majority class
```{r}
library(unbalanced)
undersampled_data <- ubBalance(data, 
                               as.factor(data$hospital_death), 
                               type='ubUnder',         # Option for under sampling
                               verbose = TRUE)
```

```{r}
usamp_data <- cbind(undersampled_data$X,    # combine output
                               undersampled_data$Y)

names(usamp_data)[names(usamp_data) == "undersampled_data$Y"] <- "Class" # change name to class
levels(usamp_data$Class) <- c('1', '0')
```

```{r}
table(usamp_data$hospital_death)
```

```{r}
# ploting number of cases in undersampled dataset
ggplot(data = usamp_data, aes(fill = Class))+
    geom_bar(aes(x = Class))+
    ggtitle("Number of samples in each class after undersampling", 
            subtitle="Total samples: 15830")+
     xlab("hospital death")+
     ylab("Samples")+
     scale_y_continuous(expand = c(0,0))+
     scale_x_discrete(expand = c(0,0))+
     theme(legend.position = "none", 
           legend.title = element_blank(),
           panel.grid.major = element_blank(),
           panel.grid.minor = element_blank(),
           panel.background = element_blank())
```


# Model1: K- nearest neighbors to predict whether a patient admitted in the hospital will survive or not?

```{r}
# Basic KNN model
# Data partition: randomly split the dataset into a train (70%) and a test set (30%)
index <- 1:nrow(usamp_data)
set.seed(123)
train_index <- sample(index, round(length(index)*0.7))
train_set <- usamp_data[train_index,]
test_set <- usamp_data[-train_index,]
```

```{r}

#train_set$hospital_death <- as.factor(ifelse(train_set$hospital_death=='Yes', 1, 0))
#test_set$hospital_death <- as.factor(ifelse(test_set$hospital_death=='Yes', 1, 0))
```


```{r}
library(class)
# Select the true values of the response in training set
cl <- train_set[,"hospital_death"]
# Using knn for k = 5, 20
knn5 <- knn(train_set[,-1],test_set[,-1], cl, k = 5)
```

```{r}
# Confusion matrix and statistics, k = 5
confusionMatrix(as.factor(knn5),as.factor(test_set$hospital_death),positive = "0")
```

# Hyper parameter tuning for knn
```{r}
accuracy <- NULL
sensitivity <-NULL
specificity <- NULL
  
for(i in 1:30) {
  knn.fit <- knn(train_set[,-1],test_set[,-1], cl, k = i)
  accuracy <- c(accuracy, mean(knn.fit == test_set$hospital_death))
  sensitivity <- c(sensitivity, sensitivity(as.factor(knn.fit),as.factor(test_set$hospital_death), positive = "1"))
  specificity <- c(specificity, specificity(as.factor(knn.fit),as.factor(test_set$hospital_death), negative = "0"))
}

balanced_accuracy = (sensitivity + specificity)/2
```

```{r}
plot(1:30, accuracy, type = "l" ,col = "red", 
     ylab = "Measures", xlab = "k",ylim = c(0.0, 1.0))

lines(1:30, sensitivity, type = "l", col = "blue")

lines(1:30, specificity, type = "l", col = "green")

lines(1:30, balanced_accuracy, type = "l", col = "orange")

legend("topright", legend = c("accuracy","sensitivity","specificity", "balanced accuracy"),
       col = c("red","blue","green","orange"), lty = 1)
```

The results of the plot show that the tuned hyper parameters with model performance measures attain stability at k = 10, so we can try running k with value 10. 

```{r}
# Using optimal parameter k = 10 
knn10 <- knn(train_set[,-1],test_set[,-1], cl, k = 10)
```

```{r}
confusionMatrix(as.factor(knn10),as.factor(test_set$hospital_death),positive = "0")
```

From the optimal parameter result, we can see that k with optimal parameter as 10 has not made much improvement in the result. **Therefore the chance of an admitted patient surviving in a hospital is 68%**  

#OverSampling data

```{r}
oversampled_data <- ubBalance(data,
                        as.factor(data$hospital_death), 
                        type='ubOver',         # Option for oversampling
                        k = 0,                 # Value of 0 creates 50:50 split
                        verbose = TRUE)
```


```{r}
osamp_data <- cbind(oversampled_data$X,    # combine output
                               oversampled_data$Y)

names(osamp_data)[names(osamp_data) == "oversampled_data$Y"] <- "Class" # change name to class
levels(osamp_data$Class) <- c('1', '0')
```


```{r}
table(osamp_data$hospital_death)
```

```{r}
# ploting number of cases in undersampled dataset
ggplot(data = osamp_data, aes(fill = Class))+
    geom_bar(aes(x = Class))+
    ggtitle("Number of samples in each class after undersampling", 
            subtitle="Total samples: 15830")+
     xlab("hospital death")+
     ylab("Samples")+
     scale_y_continuous(expand = c(0,0))+
     scale_x_discrete(expand = c(0,0))+
     theme(legend.position = "none", 
           legend.title = element_blank(),
           panel.grid.major = element_blank(),
           panel.grid.minor = element_blank(),
           panel.background = element_blank())
```


# Model2: Logistic Regression

```{r}
# Logistic regression
logit1.fit <- glm(hospital_death ~ apache_2_diagnosis,
                  family=binomial(link='logit'),data = osamp_data) # oversampled 

summary(logit1.fit)
```

```{r}
# Calculate predicted probability
logit1.prob <- predict(logit1.fit, type = "response")

plot(x = data$hospital_death, y = ifelse(data$hospital_death == "Yes", 1, 0), 
     col = "orange", xlab = "Apache 2 diagnosis", ylab = "Probability of Death")

points(x = data$hospital_death[order(data$hospital_death)], 
       y = logit1.prob[order(data$hospital_death)], 
       type = "l", col="blue", lwd = 2)


# the blue curve represents the probability function. Probability in range 0 to 1
```

```{r}
# Logistic regression
logit2.fit <- glm(hospital_death ~ apache_3j_diagnosis,
                  family=binomial(link='logit'),data = osamp_data)

summary(logit2.fit)
```

```{r}
# Logistic regression
logit3.fit <- glm(hospital_death ~ apache_2_diagnosis + apache_3j_diagnosis,
                  family=binomial(link='logit'),data = osamp_data)

summary(logit3.fit)
```

```{r}
# Logistic regression with all predictors related to admitted patient's survival in a hospital
logit.fit <- glm(hospital_death ~ apache_2_diagnosis + apache_3j_diagnosis + heart_rate_apache + map_apache + resprate_apache + temp_apache,
                 family=binomial(link='logit'),data = osamp_data)

summary(logit.fit)
```

```{r}
# Get coefficient estimates
coef(logit.fit)
```

```{r}
# Get coefficient estimates with statistics
summary(logit.fit)$coef
```

```{r}
# Get p-values for all coefficient estimates
summary(logit.fit)$coef[,4]
```

# Interpreting logistic regression
```{r}
library(stargazer)
stargazer(logit1.fit, logit2.fit, logit3.fit, logit.fit, 
          type = "text",star.cutoffs = c(0.05, 0.01, 0.001),
          title="Logistic Regression", digits=4)
```

# Calculating McFadden Pseudo R Squared by sung the pscl package

```{r}
library(pscl)
pR2(logit.fit)
```

# Manually calculating pseudo R Squared
```{r}
# Fit the null model
logit.null.fit <- glm(hospital_death ~ 1,family=binomial(link='logit'),data=osamp_data)

# Show the log likelihood of the null model
logLik(logit.null.fit)
```

# Prediction using logistic regression
# In-sample prediction
```{r}
# Calculate probability of default
logit.probs <- predict(logit.fit,type="response")

# Show the first 10 values
logit.probs[1:10]
```

```{r}
# Calculate predicted default
logit.pred <- ifelse(logit.probs >.5, "1", "0")

# Show confusion matrix
table(Prediction=logit.pred, Truth=osamp_data$hospital_death)
```

```{r}
# Calculate in-sample prediction accuracy
mean(logit.pred == osamp_data$hospital_death)
```

# logistic regression prediction accuracy
```{r}
confusionMatrix(factor(logit.pred),as.factor(osamp_data$hospital_death), positive = "0")

sensitivity(factor(logit.pred),as.factor(osamp_data$hospital_death), positive = "0")

specificity(factor(logit.pred),as.factor(osamp_data$hospital_death), negative = "1")
```

# logistic regression "Out of sample prediction"

Using 70%-30% split with sample() method for random sampling with over sampled data
```{r}
index <- 1:nrow(osamp_data)
set.seed(123)
train_index <- sample(index, round(length(index)*0.7))
train_set <- osamp_data[train_index,]
test_set <- osamp_data[-train_index,]
```

```{r}
# Train the logistic regression model
logit.fit.train <- glm(hospital_death ~ apache_2_diagnosis + 
                         apache_3j_diagnosis + heart_rate_apache + 
                         map_apache + resprate_apache + temp_apache, 
                       family=binomial(link='logit'),data = train_set)

summary(logit.fit.train)
```

Comparing full model and model trained using training data set. 
```{r}
stargazer(logit.fit, logit.fit.train, type = "text",star.cutoffs = c(0.05, 0.01, 0.001),
          title="Logistic Regression", digits=4)
```

```{r}
# Calculate probability of default
test_probs <- predict(logit.fit.train, newdata = test_set, type="response")

# Show the first 10 values
test_probs[1:10]
```

```{r}
# Calculate predicted default
test_pred <- ifelse(test_probs >.5, "1", "0")

# Show confusion matrix
confusionMatrix(factor(test_pred),as.factor(test_set$hospital_death))
```



```{r}
stopCluster(cl)
```

