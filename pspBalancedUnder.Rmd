---
title: "Patient Survival Prediction Project"
author: "Adam Crawford, Adam Baer, Austin Funcheon, Viraj Rane"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Data

```{r}
df <- read.csv("dataset.csv")

#str(df)
#summary(df)

library("dplyr")
library("ggpubr")
library(tree)
library(caret)
library(randomForest)
library(lattice)
library(dplyr)
library(lubridate)
library(doParallel)
library(smotefamily)
library(ROSE)
cl <- makePSOCKcluster(detectCores() -1)
registerDoParallel(cl)
set.seed(123)

library(ggplot2)
#ggplot(df, aes(factor(hospital_death))) +
#  geom_bar()
```

# Data Preparation


```{r}

#keep original copy of df for trim work.
dfOriginal <- df
#df$encounter_id <- df$patient_id <- df$hospital_id <- df$X <- NULL

# get rid of identifiers and random X column
#removal of apache variables.
df$encounter_id <- df$patient_id <- df$hospital_id <- df$X <- df$apache_4a_hospital_death_prob <- df$apache_4a_icu_death_prob <- df$apache_3j_diagnosis <- df$apache_3j_diagnosis <- NULL
df0 <- df
# change columns to factors
factors <- c("elective_surgery","ethnicity","gender","icu_admit_source",
             "icu_stay_type","icu_type","apache_post_operative","arf_apache",
             "gcs_eyes_apache","gcs_motor_apache","gcs_unable_apache","gcs_verbal_apache",
             "intubated_apache","ventilated_apache","aids","cirrhosis",
             "diabetes_mellitus","hepatic_failure","immunosuppression","leukemia",
             "lymphoma","solid_tumor_with_metastasis", "hospital_death")

#factors <- c("elective_surgery","ethnicity","gender","icu_admit_source",
#             "icu_stay_type","icu_type","apache_post_operative","arf_apache",
#             "gcs_eyes_apache","gcs_motor_apache","gcs_unable_apache","gcs_verbal_apache",
#             "intubated_apache","ventilated_apache","aids","cirrhosis",
#             "diabetes_mellitus","hepatic_failure","immunosuppression","leukemia",
#             "lymphoma","solid_tumor_with_metastasis","apache_3j_bodysystem",
#             "hospital_death")
df[factors] <- lapply(df[factors], factor)

#table(df$hospital_death)

df0 <- df # keeping an origin copy of df. I suspect we don't want to blanket kill all the omits if we later find those factors are irrelevant. our dataset cuts in half ~Austin



#dfBal <- ovun.sample(hospital_death~., data = df, method = "over", N = 70000)$data

#df0Bal <- dfBal

#summary(dfBal)

#table(df$hospital_death)
#table(dfBal$hospital_death)



```

```{r}
df <- na.omit(df)
```



```{r}
# split data into training data and testing data
#these variables are only used for first pass. Use trim_train_data and trim_test_data instead after bottom 30 variables reduced.

train <- sample(1:nrow(df), nrow(df)*0.7)
train_data <- df[train,]
test_data <- df[-train,]

table(train_data$hospital_death)
train_data0 <- train_data
train_data0
dfBal <- ovun.sample(hospital_death~., data = train_data, method = "under", N = 7400)$data

df0Bal <- dfBal
train_data <- dfBal
```

```{r}
#Crawford
library(tree)

#this doesn't work
first_tree <- tree(as.factor(hospital_death) ~., data = train_data)
summary(first_tree)
plot(first_tree)
text(first_tree, cex = 0.75, col = 'red')
```

```{r}
#Austin Fit a random forest for variable selection, run time ~7.5 minutes
library(randomForest)
#set.seed(123)
start_t <- Sys.time()
cat("",cat(" Variable selection Training started at:",format(start_t, "%a %b %d %X %Y")))

#run a prelim rf for variable summary. 
rf_eval <- randomForest(hospital_death~., data = train_data,
                           mtry = 5, importance = TRUE)

rf_eval
varImpPlot(rf_eval) #plot relevance plot

finish_t <- Sys.time()
cat("",cat("Variable selection Training finished at:",format(finish_t, "%a %b %d %X %Y")))

cat("Variable selection The training process finished in",difftime(finish_t,start_t,units="mins"), "minutes")


```

```{r} 
#Austin Identify the lowest impact variables from the RF run
rfImp <- importance(rf_eval)
#rfImp

rf_Imp_Sort <- as.data.frame.matrix(rfImp)
#adds a column for accuracy*gini for overall variable impact
rf_Imp_Sort$cross <- rf_Imp_Sort$MeanDecreaseAccuracy*rf_Imp_Sort$MeanDecreaseGini
#rf_Imp_Sort
#adds an overall rank of impact of variable, with bigger being biggest ranked impact, with 1 being lowest impact
rf_Imp_Sort$rank <- rank(rf_Imp_Sort$cross)
#rf_Imp_Sort

#variables ranked by cross order
rf_Imp_SO <- rf_Imp_Sort[order(-rf_Imp_Sort$cross),]
#rf_Imp_SO
#variable list sorted by importance. Accuracy * Gini
```

```{r} 
#Austin Check accuracy score against test data.
rf_yhat <- predict(rf_eval, newdata = test_data)
#accuracy score of mtry 5 rf used for variable selection
rfscore <- postResample(rf_yhat, test_data$hospital_death)
print(rfscore)
```
 Accuracy     Kappa 
0.7668741 0.2620111 
```{r}
#Austin 
rfVarDrop <-rf_Imp_Sort
#trim the bottom x predictors
rfVarDrop <- rfVarDrop %>% filter(rank <= 25)

dropVar <- row.names(rfVarDrop) #Variables to drop list 

#make a shorter list of variables from rf variable selection
dfTrim <- df0[ , ! names(df0) %in% dropVar] 
dfTrim <- na.omit(dfTrim)
#dfTrim is experimental list.

```

```{r}
#Austin create new train and test data from rf selection, with undersampling enabled for training set.
train2 <- sample(1:nrow(dfTrim), nrow(dfTrim)*0.7)
trim_train_data <- dfTrim[train2,]
trim_test_data <- dfTrim[-train2,]
#str(dfTrim)

table(trim_train_data$hospital_death)
trim_train_data0 <- trim_train_data
#trim_train_data0
trim_dfBal <- ovun.sample(hospital_death~., data = trim_train_data, method = "under", N = 9200)$data

df0Bal <- trim_dfBal
trim_train_data <- trim_dfBal
```

```{r}
#Austin  #30 second run time with 4 cores
start_t <- Sys.time()
cat("",cat("Trimmed Training started at:",format(start_t, "%a %b %d %X %Y")))

rf_eval2 <- randomForest(hospital_death~., data = trim_train_data,
                           mtry = 5, importance = TRUE)

rf_eval2
varImpPlot(rf_eval2)

finish_t <- Sys.time()
cat("",cat("Trimmed Training finished at:",format(finish_t, "%a %b %d %X %Y")))

cat("Trimmed The training process finished in",difftime(finish_t,start_t,units="mins"), "minutes")
```

```{r} 
#Austin
#Check accuracy score
rf_yhat2 <- predict(rf_eval2, newdata = trim_test_data)
#accuracy score of mtry 5 rf used for variable selection
rfscore2 <- postResample(rf_yhat2, trim_test_data$hospital_death)
rfscore2
#rfscore
```
 Accuracy     Kappa       
0.7668741 0.2620111         first pass
0.7796420 0.2787223         with bottom 30 var dropped
0.7757662 0.2726710         35
0.7840903 0.2901965         25
0.7684269 0.2677715         50
0.6134630 0.1374592         70
0.7532852 0.2252227         65
0.7641030 0.2564636         60
```{r}
#Austin
print("Drop List")
rownames(rfVarDrop)

print("Keep List")
colnames(dfTrim)
```

```{r}
#Austin Run Tune on RF  took 8 minute s with 4:15
tuneGrid <- data.frame(mtry = 4:15)
#tuneGrid <- data.frame(mtry = 4:15)
#tuneGrid value came out 9.


control <- trainControl(method = 'cv', number = 5)
# print out system time before training
start_t <- Sys.time()
cat("",cat("RFtune Training started at:",format(start_t, "%a %b %d %X %Y")))

rftrim_tuned <- train(hospital_death ~ ., data = trim_train_data,
                  method = 'rf',
                  trControl = control,
                  tuneGrid = tuneGrid)

# print out system time after training
finish_t <- Sys.time()
cat("",cat("RFTune Training finished at:",format(finish_t, "%a %b %d %X %Y")))

cat(" RFTune The training process finished in",difftime(finish_t,start_t,units="mins"), "minutes")

print(rftrim_tuned)

#
```

```{r} 
#Check accuracy score of RF tuned
rf_yhat_tuned <- predict(rftrim_tuned, newdata = trim_test_data)
#accuracy score of mtry 5 rf used for variable selection
rfscore_tuned <- postResample(rf_yhat_tuned, trim_test_data$hospital_death)
#rfscore_tuned

print(rfscore_tuned)

confusionMatrix(rf_yhat_tuned, trim_test_data$hospital_death)
```

```{r}
stopCluster(cl)
```
